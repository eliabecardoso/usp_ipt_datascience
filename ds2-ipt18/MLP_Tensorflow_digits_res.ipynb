{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP_Tensorflow_digits_res.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e91uVEYQJvlb",
        "colab_type": "text"
      },
      "source": [
        "## MLP_Tensorflow_digits_res"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9gFDAtYvNRPE",
        "outputId": "e24f6cec-db92-440c-a691-e38daa8281c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_digits\n",
        "import matplotlib.pyplot as plt\n",
        "import random as r\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QKY57AV9W4rw",
        "outputId": "a233a146-8bb0-4be6-9458-5958f7b8ec03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "source": [
        "\n",
        "#importa a base de dígitos em tupla\n",
        "\n",
        "digits1 = load_digits(return_X_y=True)\n",
        "# em digits1[0] : vetores da imagem\n",
        "# em digits1[1] : classes reais das imagens (dígitos)\n",
        "X=np.array(list(digits1[0]))\n",
        "Y=np.array(list(digits1[1]))\n",
        "\n",
        "plt.gray() \n",
        "plt.matshow(X[0].reshape((8,8))) \n",
        "plt.show() \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "enc = OneHotEncoder()\n",
        "YC=Y.copy()\n",
        "YR=YC.reshape((-1,1))\n",
        "print(YR)\n",
        "enc.fit(YR)\n",
        "YH=enc.transform(YR).toarray()\n",
        "print(YH[0])\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAECCAYAAADXWsr9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 288x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[0]\n",
            " [1]\n",
            " [2]\n",
            " ...\n",
            " [8]\n",
            " [9]\n",
            " [8]]\n",
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EE_wdBh_bKwp",
        "colab": {}
      },
      "source": [
        "W = {'hidden': tf.Variable(tf.random_normal([64, 20])),\n",
        "     'output': tf.Variable(tf.random_normal([20, 10]))}\n",
        "\n",
        "    \n",
        "b = {'hidden': tf.Variable(tf.random_normal([20])),\n",
        "     'output': tf.Variable(tf.random_normal([10]))}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Rw5mia8rZgMF",
        "colab": {}
      },
      "source": [
        "xx = tf.placeholder('float', [None, 64])\n",
        "yy = tf.placeholder('float', [None, 10])\n",
        "\n",
        "def rede(xx,W,b):\n",
        "  hidden = tf.nn.relu(tf.add(tf.matmul(xx, W['hidden']), b['hidden']))\n",
        "  return tf.add(tf.matmul(hidden, W['output']), b['output'])\n",
        "\n",
        "model=rede(xx,W,b)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InmY5_sDMoza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, YH, test_size=0.30, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wd2G5AphWpAB",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = model, labels = y_train))\n",
        "opt = tf.train.AdamOptimizer(learning_rate = 0.01).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xIWWzGIrWCLq",
        "outputId": "882e0e81-1778-4511-d1ff-1b4752a4c0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for epoca in range(10000):\n",
        "        sess.run(opt,feed_dict = {xx: X_train, yy: y_train})\n",
        "        if epoca%100==0:print(epoca,sess.run(loss,feed_dict={xx:X_train,yy:y_train}).mean())\n",
        "    W_final, b_final = sess.run([W, b])\n",
        "    ye_train=sess.run(tf.nn.softmax(model),feed_dict = {xx:X_train})\n",
        "    ye_test=sess.run(tf.nn.softmax(model),feed_dict = {xx:X_test})\n",
        "    \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 279.17618\n",
            "100 3.5107982\n",
            "200 0.9273566\n",
            "300 0.4528861\n",
            "400 0.2680829\n",
            "500 0.18659198\n",
            "600 0.14325508\n",
            "700 0.117114194\n",
            "800 0.10180339\n",
            "900 0.08867403\n",
            "1000 0.0786292\n",
            "1100 0.07153816\n",
            "1200 0.06617653\n",
            "1300 0.062068604\n",
            "1400 0.05906607\n",
            "1500 0.056588694\n",
            "1600 0.054321058\n",
            "1700 0.05268793\n",
            "1800 0.051260214\n",
            "1900 0.050025623\n",
            "2000 0.049028732\n",
            "2100 0.04816767\n",
            "2200 0.047396127\n",
            "2300 0.04666857\n",
            "2400 0.045907382\n",
            "2500 0.04528682\n",
            "2600 0.044764247\n",
            "2700 0.043423142\n",
            "2800 0.04231589\n",
            "2900 0.04179473\n",
            "3000 0.04136694\n",
            "3100 0.041008387\n",
            "3200 0.039938215\n",
            "3300 0.039327864\n",
            "3400 0.038939293\n",
            "3500 0.03858094\n",
            "3600 0.03727783\n",
            "3700 0.03666589\n",
            "3800 0.036180347\n",
            "3900 0.03573498\n",
            "4000 0.035370346\n",
            "4100 0.03499582\n",
            "4200 0.03473047\n",
            "4300 0.03270917\n",
            "4400 0.03223413\n",
            "4500 0.031987533\n",
            "4600 0.03175089\n",
            "4700 0.031514402\n",
            "4800 0.0315716\n",
            "4900 0.030376116\n",
            "5000 0.02951819\n",
            "5100 0.029069431\n",
            "5200 0.02873986\n",
            "5300 0.02847982\n",
            "5400 0.028129434\n",
            "5500 0.022636347\n",
            "5600 0.022034893\n",
            "5700 0.021726446\n",
            "5800 0.021567164\n",
            "5900 0.021413295\n",
            "6000 0.02087204\n",
            "6100 0.0204411\n",
            "6200 0.020279616\n",
            "6300 0.02012258\n",
            "6400 0.019982744\n",
            "6500 0.018436579\n",
            "6600 0.017913397\n",
            "6700 0.017782975\n",
            "6800 0.017238162\n",
            "6900 0.017120933\n",
            "7000 0.017059894\n",
            "7100 0.016984412\n",
            "7200 0.016941177\n",
            "7300 0.016907288\n",
            "7400 0.016871564\n",
            "7500 0.01683766\n",
            "7600 0.016221313\n",
            "7700 0.016157506\n",
            "7800 0.015391247\n",
            "7900 0.015323697\n",
            "8000 0.018134033\n",
            "8100 0.0177673\n",
            "8200 0.017671917\n",
            "8300 0.017460054\n",
            "8400 0.01740141\n",
            "8500 0.01735136\n",
            "8600 0.017309928\n",
            "8700 0.017273901\n",
            "8800 0.01723401\n",
            "8900 0.017190905\n",
            "9000 0.016289586\n",
            "9100 0.016258612\n",
            "9200 0.016228283\n",
            "9300 0.015767794\n",
            "9400 0.0141759915\n",
            "9500 0.012538959\n",
            "9600 0.007071015\n",
            "9700 0.006430656\n",
            "9800 0.006364551\n",
            "9900 0.0063271318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFeibrLMQQKv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ye_tr=np.array([np.argmax(y) for y in ye_train])\n",
        "ye_ts=np.array([np.argmax(y) for y in ye_test])\n",
        "yt=np.array([np.argmax(y) for y in y_train])\n",
        "yts=np.array([np.argmax(y) for y in y_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfnT9YSaQwTy",
        "colab_type": "code",
        "outputId": "119b0e1e-23da-44d3-ae0d-a1ef7d0bd0b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(ye_tr,yt),accuracy_score(ye_ts,yts)\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.9960222752585521, 0.9111111111111111)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOQsGbdORvQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}